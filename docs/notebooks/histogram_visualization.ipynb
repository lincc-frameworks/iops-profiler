{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Histogram Visualization\n",
    "\n",
    "This notebook demonstrates how to use the histogram feature to visualize I/O operation distributions.\n",
    "\n",
    "**Note:** Histogram mode is available on Linux (with strace) and macOS (with fs_usage), but not on Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Load the extension and prepare our test environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext iops_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create a temporary directory\n",
    "test_dir = tempfile.mkdtemp()\n",
    "print(f\"Working directory: {test_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Basic Histogram Example\n",
    "\n",
    "Let's start with a simple example that creates files of different sizes. The `--histogram` flag enables visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%iops --histogram\n",
    "# Create files with varying sizes\n",
    "for i in range(5):\n",
    "    filename = os.path.join(test_dir, f'file_{i}.txt')\n",
    "    # Size increases exponentially: 1KB, 10KB, 100KB, 1MB, 10MB\n",
    "    size = 1024 * (10 ** i)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('x' * size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "The histogram shows two charts:\n",
    "\n",
    "1. **Operation Count Distribution**: How many operations fall into each size bucket\n",
    "2. **Total Bytes Distribution**: Total bytes transferred in each size bucket\n",
    "\n",
    "Both use logarithmic scale on the x-axis to show the wide range of operation sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Read Operations Histogram\n",
    "\n",
    "Now let's read the files back and see the read operation distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%iops --histogram\n",
    "# Read files of different sizes\n",
    "for i in range(5):\n",
    "    filename = os.path.join(test_dir, f'file_{i}.txt')\n",
    "    with open(filename, 'r') as f:\n",
    "        content = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Notice how the distribution might differ from writes:\n",
    "- Operating system may cache recently written data\n",
    "- Read buffering strategies may differ from write buffering\n",
    "- Some reads might be satisfied from memory cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Mixed Read/Write Operations\n",
    "\n",
    "Let's see what happens when we mix read and write operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%iops --histogram\n",
    "# Write small files\n",
    "for i in range(10):\n",
    "    small_file = os.path.join(test_dir, f'small_{i}.txt')\n",
    "    with open(small_file, 'w') as f:\n",
    "        f.write('data' * 256)  # ~1KB each\n",
    "\n",
    "# Write medium files\n",
    "for i in range(5):\n",
    "    medium_file = os.path.join(test_dir, f'medium_{i}.txt')\n",
    "    with open(medium_file, 'w') as f:\n",
    "        f.write('data' * 2560)  # ~10KB each\n",
    "\n",
    "# Write large file\n",
    "large_file = os.path.join(test_dir, 'large.txt')\n",
    "with open(large_file, 'w') as f:\n",
    "    f.write('data' * 256000)  # ~1MB\n",
    "\n",
    "# Now read some files back\n",
    "for i in range(5):\n",
    "    with open(os.path.join(test_dir, f'small_{i}.txt'), 'r') as f:\n",
    "        _ = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The histogram now shows separate lines for:\n",
    "- **Reads** (one color)\n",
    "- **Writes** (another color)  \n",
    "- **All operations** combined (third color)\n",
    "\n",
    "This makes it easy to see how read and write patterns differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Analyzing Buffer Size Impact\n",
    "\n",
    "One practical use of histograms is to analyze how buffer sizes affect I/O patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%iops --histogram\n",
    "# Small buffer size (default)\n",
    "test_file = os.path.join(test_dir, 'buffer_test.txt')\n",
    "with open(test_file, 'w') as f:\n",
    "    for i in range(1000):\n",
    "        f.write('x' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%iops --histogram\n",
    "# Larger buffer size\n",
    "test_file_buffered = os.path.join(test_dir, 'buffer_test_large.txt')\n",
    "with open(test_file_buffered, 'w', buffering=8192) as f:\n",
    "    for i in range(1000):\n",
    "        f.write('x' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Compare the two histograms:\n",
    "- The larger buffer may result in fewer, larger operations\n",
    "- This can improve throughput but increase latency\n",
    "- The histogram makes the difference visually clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Real-World Example: CSV Writing\n",
    "\n",
    "Let's look at a more realistic scenario - writing CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%iops --histogram\n",
    "import csv\n",
    "\n",
    "csv_file = os.path.join(test_dir, 'data.csv')\n",
    "with open(csv_file, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write header\n",
    "    writer.writerow(['id', 'name', 'value', 'description'])\n",
    "    # Write data rows\n",
    "    for i in range(1000):\n",
    "        writer.writerow([i, f'item_{i}', i * 1.5, f'Description for item {i}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "The histogram reveals:\n",
    "- How the CSV writer batches operations\n",
    "- Whether writes are uniform or variable in size\n",
    "- Opportunities for optimization (e.g., adjusting buffer size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Understanding the Histogram\n",
    "\n",
    "### X-axis: Bytes per Operation (log scale)\n",
    "Shows the size of individual I/O operations. The logarithmic scale allows you to see both tiny (< 1KB) and large (> 1MB) operations on the same chart.\n",
    "\n",
    "### Y-axis (Top chart): Operation Count\n",
    "How many operations fall into each size bucket. Helps identify the most common operation sizes.\n",
    "\n",
    "### Y-axis (Bottom chart): Total Bytes\n",
    "Total bytes transferred in each size bucket. Shows which operation sizes contribute most to overall data transfer.\n",
    "\n",
    "### Interpretation Tips\n",
    "- **Many small operations**: May indicate inefficient buffering\n",
    "- **Few large operations**: Usually more efficient for throughput\n",
    "- **Bimodal distribution**: Suggests different types of operations (e.g., metadata vs. data)\n",
    "- **Read vs. Write differences**: May reveal caching or buffering strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(test_dir)\n",
    "print(\"Cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned:\n",
    "\n",
    "1. How to enable histogram visualization with `--histogram`\n",
    "2. Interpreting operation count and bytes distribution charts\n",
    "3. Analyzing read vs. write patterns\n",
    "4. Using histograms to optimize buffer sizes\n",
    "5. Applying histogram analysis to real-world scenarios\n",
    "\n",
    "Histograms are particularly useful for:\n",
    "- Understanding I/O patterns in complex code\n",
    "- Identifying inefficiencies (many small operations)\n",
    "- Optimizing buffer and chunk sizes\n",
    "- Comparing different implementation strategies\n",
    "\n",
    "**Remember:** Histogram mode is only available on Linux and macOS, not on Windows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
